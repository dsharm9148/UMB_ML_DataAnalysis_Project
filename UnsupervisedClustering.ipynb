{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d263123-4f5e-4fdc-bf51-5d096ef29e3a"
      },
      "source": [
        "#### Data extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "8ba584a4-69e7-44c0-9ea5-e50c8ba0c390",
        "outputId": "1f66f12e-756f-4f75-8f6e-2aecab0df27b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/diyasharma/Documents/LabProject/features_filtered.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-081ea8693964>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/diyasharma/Documents/LabProject/features_filtered.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/diyasharma/Documents/LabProject/features_filtered.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Read the CSV file\n",
        "file_path = '/Users/diyasharma/Documents/LabProject/features_filtered.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "data = data.dropna()\n",
        "\n",
        "# Assuming the target class column is named 'Marker' and we need to exclude it for UMAP\n",
        "features = data.drop(columns=['Marker'])\n",
        "target = data['Marker']\n",
        "\n",
        "features.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb63291c-e1d6-43e4-a7e8-5825c2a8615b"
      },
      "source": [
        "#### UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85823c56-0d75-48bf-8018-bb79e2208e86"
      },
      "outputs": [],
      "source": [
        "import umap\n",
        "\n",
        "# Run UMAP\n",
        "umap_model = umap.UMAP(n_neighbors=5, min_dist=0.0)\n",
        "umap_embedding = umap_model.fit_transform(features)\n",
        "\n",
        "# Add UMAP results to the dataframe\n",
        "umap_df = pd.DataFrame(umap_embedding, columns=['UMAP1', 'UMAP2'])\n",
        "umap_df['Marker'] = target\n",
        "umap_df.head()\n",
        "\n",
        "# Save UMAP results to a new CSV file if needed\n",
        "#output_file_path = '/Users/diyasharma/Documents/LabProject/umap_results.csv'\n",
        "#umap_df.to_csv(output_file_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7e07058-8f7a-4303-b9bc-68c9615820bc"
      },
      "source": [
        "#### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e29efac-53c7-4347-b1cc-83f96d95131d"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import combinations\n",
        "\n",
        "# Define markers\n",
        "markers = [\"GFP\", \"CCK\", \"PV\", \"SST\", \"NPY\", \"VIP\"]\n",
        "\n",
        "# Define a color palette and create a mapping from marker to color\n",
        "palette = sns.color_palette(\"bright\", len(markers))\n",
        "marker_color_map = {marker: palette[i] for i, marker in enumerate(markers)}\n",
        "\n",
        "# Plot UMAP for all markers\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='Marker', palette=marker_color_map, s=5, edgecolor=None)\n",
        "plt.title('UMAP Projection of All Markers', fontsize=16)\n",
        "plt.legend(title='Marker')\n",
        "plt.show()\n",
        "\n",
        "# Plot UMAP for each marker individually\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, marker in enumerate(markers):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "\n",
        "    plt.scatter(umap_df['UMAP1'], umap_df['UMAP2'], c='wheat', s=1)\n",
        "\n",
        "    marker_indices = umap_df[umap_df['Marker'] == marker].index\n",
        "    plt.scatter(umap_df.loc[marker_indices, 'UMAP1'], umap_df.loc[marker_indices, 'UMAP2'], c=[marker_color_map[marker]], s=.5)\n",
        "\n",
        "    plt.gca().set_aspect('equal', 'datalim')\n",
        "    plt.title(f'UMAP projection - {marker}', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Create a function to plot one-vs-one classification\n",
        "def plot_one_vs_one(marker1, marker2, ax):\n",
        "    subset = umap_df[(umap_df['Marker'] == marker1) | (umap_df['Marker'] == marker2)]\n",
        "    subset_palette = {marker1: marker_color_map[marker1], marker2: marker_color_map[marker2]}\n",
        "    sns.scatterplot(data=subset, x='UMAP1', y='UMAP2', hue='Marker', palette=subset_palette, s=5, edgecolor=None, ax=ax)\n",
        "    ax.set_title(f'{marker1} vs {marker2}', fontsize=14)\n",
        "    ax.legend(title='Marker')\n",
        "\n",
        "# Create subplots for each pair of markers\n",
        "fig, axes = plt.subplots(nrows=5, ncols=3, figsize=(15, 20))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Generate plots for each pair of markers\n",
        "for idx, (marker1, marker2) in enumerate(combinations(markers, 2)):\n",
        "    plot_one_vs_one(marker1, marker2, axes[idx])\n",
        "\n",
        "# Hide any unused subplots\n",
        "for ax in axes[idx+1:]:\n",
        "    ax.set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e883123-10b6-4ac2-9350-e60bb6baaad5"
      },
      "source": [
        "#### Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3ce90bd-4785-4114-893c-243701e98b01"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import HDBSCAN\n",
        "\n",
        "# initialize clusterer\n",
        "clusterer = HDBSCAN(min_cluster_size=500)\n",
        "clusterer.fit(umap_df[['UMAP1', 'UMAP2']])\n",
        "\n",
        "# Add cluster labels to the original DataFrame\n",
        "umap_df['Cluster'] = clusterer.labels_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49112d98-aa64-4cc1-a234-8971f58ae9bd"
      },
      "source": [
        "#### Visualization HDBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f27ad28-bd32-4f7b-92d8-66f167d56a9b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define colors for clusters\n",
        "unique_clusters = np.unique(clusterer.labels_)\n",
        "num_clusters = len(unique_clusters)\n",
        "palette = sns.color_palette(\"bright\", num_clusters)\n",
        "\n",
        "# Check if cluster group -1 exists\n",
        "if -1 in unique_clusters:\n",
        "    # Change color of cluster group -1 to grey\n",
        "    palette[unique_clusters.tolist().index(-1)] = (0.7, 0.7, 0.7)\n",
        "\n",
        "# Plot all data points in one plot, color-coded by cluster labels\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='Cluster', palette=palette, s=3, legend='full')\n",
        "plt.gca().set_aspect('equal', 'datalim')\n",
        "plt.title('UMAP projection with HDBSCAN clusters', fontsize=18)\n",
        "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eea36401-e8f4-42ef-958b-64cb97e30e1b"
      },
      "source": [
        "#### Calculating Percentages per Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eec092de-7a86-4b10-adfb-3a64fdea8815"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def count_markers(df):\n",
        "    # Initialize a defaultdict to store counts of markers within each cluster\n",
        "    count_dict = defaultdict(int)\n",
        "\n",
        "    # Iterate through each row of the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        # Create a key for the count_dict by combining 'Cluster' and 'Marker' values\n",
        "        Cluster = f\"Cluster {row['Cluster']} - {row['Marker']}\"\n",
        "        # Increment the count for this Cluster-Marker combination\n",
        "        count_dict[Cluster] += 1\n",
        "\n",
        "    # Return the dictionary containing counts for each Cluster-Marker combination\n",
        "    return count_dict\n",
        "\n",
        "def create_summary_dataframe(count_dict):\n",
        "    # Extract a sorted list of unique cluster identifiers from the count_dict keys\n",
        "    Clusters = sorted(set(Cluster.split(\" - \")[0] for Cluster in count_dict.keys()))\n",
        "\n",
        "    # Initialize a dictionary to hold the summary data, starting with the cluster names\n",
        "    data = {'Cluster': Clusters}\n",
        "\n",
        "    # For each marker, populate the dictionary with counts of cells in each cluster\n",
        "    for marker in ['GFP', 'PV', 'CCK', 'SST', 'NPY', 'VIP']:\n",
        "        # Retrieve the count for each marker in each cluster, defaulting to 0 if not present\n",
        "        data[f'#{marker}'] = [count_dict.get(f'{Cluster} - {marker}', 0) for Cluster in Clusters]\n",
        "\n",
        "    # Calculate the sum of marker counts for each cluster and add to the data dictionary\n",
        "    data['Sum'] = [sum(data[f'#{marker}'][i] for marker in ['GFP', 'PV', 'CCK', 'SST', 'NPY', 'VIP']) for i in range(len(Clusters))]\n",
        "\n",
        "    # Calculate the percentage of each marker within each cluster and add to the data dictionary\n",
        "    for marker in ['GFP', 'PV', 'CCK', 'SST', 'NPY', 'VIP']:\n",
        "        # Calculate the percentage and round to two decimal places\n",
        "        data[f'%{marker}'] = [round((data[f'#{marker}'][i] / data['Sum'][i]) * 100, 2) for i in range(len(Clusters))]\n",
        "\n",
        "    # Convert the dictionary to a pandas DataFrame and return it\n",
        "    return pd.DataFrame(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a9e1475-ff50-4695-b74b-568b1f303c20"
      },
      "outputs": [],
      "source": [
        "umap_df.sort_values(by=\"Cluster\")\n",
        "percents = create_summary_dataframe(count_markers(umap_df))\n",
        "percents.sort_values(by=\"Cluster\")\n",
        "# Filter columns that contain '%' in their names\n",
        "percentage_columns = [col for col in percents.columns if '%' in col]\n",
        "percentage_columns.insert(0, 'Cluster')\n",
        "\n",
        "# Display the head of the DataFrame with only percentage columns\n",
        "percents[percentage_columns].head()\n",
        "#percents.to_csv('percents.csv')"
      ]
    }
  ]
}